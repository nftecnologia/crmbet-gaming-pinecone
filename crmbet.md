ğŸš€ Prompt Claude Code UltraThink | CRM com ClusterizaÃ§Ã£o e Smart Marketing

â¸»

ğŸ§  Prompt:

âš™ï¸ Sistema: UltraThink + Hardness + Subtask

ğŸ§  InstruÃ§Ã£o:
VocÃª Ã© um arquiteto de software sÃªnior especializado em IA, Big Data, CRM e automaÃ§Ã£o. Crie um sistema completo e escalÃ¡vel baseado na seguinte descriÃ§Ã£o.

â¸»

ğŸ”¥ DescriÃ§Ã£o do Projeto:

Desenvolver um CRM Inteligente com Machine Learning, que analisa dados do Data Lake e faz clusterizaÃ§Ã£o dos usuÃ¡rios com base em comportamento de apostas, preferÃªncias de jogos, ticket mÃ©dio, dias e horÃ¡rios de atividade, alÃ©m do canal de comunicaÃ§Ã£o preferido. Esse sistema alimenta automaticamente campanhas no Smartico ou qualquer outro CRM.

â¸»

ğŸ” Regras do Sistema:
	1.	ğŸš€ Arquitetura EscalÃ¡vel: Backend robusto, com banco PostgreSQL, Redis, RabbitMQ, deploy em containers Docker (Railway).
	2.	ğŸ² Machine Learning Pipeline: ClusterizaÃ§Ã£o automÃ¡tica dos usuÃ¡rios com KMeans, DBSCAN ou HDBSCAN.
	3.	ğŸ”— Fonte de Dados: Ler dados do Data Lake (ex.: AWS S3) e da tabela tbl_transactions.
	4.	ğŸ“Š Features para ClusterizaÃ§Ã£o:
	â€¢	Jogo favorito / tipo de jogo (ex.: Crash, Cassino, Esportes)
	â€¢	Ticket mÃ©dio (baixo, mÃ©dio, alto)
	â€¢	Dias e horÃ¡rios de maior atividade
	â€¢	Canal de comunicaÃ§Ã£o preferido (SMS, WhatsApp, Email)
	5.	ğŸ§  CriaÃ§Ã£o de Clusters: Identificar grupos como:
	â€¢	Gosta de Crash e aposta alto
	â€¢	Joga mais Ã  noite
	â€¢	Prefere cashback
	6.	ğŸ”¥ DataFrame Final: Gerar tabela df_final_union com os dados do cluster e informaÃ§Ãµes enriquecidas do usuÃ¡rio.
	7.	ğŸ“¤ IntegraÃ§Ã£o CRM: Enviar os dados automaticamente para campanhas personalizadas no Smartico via API REST.
	8.	ğŸ–¥ï¸ Dashboard Operacional:
	â€¢	VisualizaÃ§Ã£o de clusters
	â€¢	AnÃ¡lise de comportamento
	â€¢	CriaÃ§Ã£o manual ou automÃ¡tica de campanhas

â¸»

ğŸ§  Tarefas em Paralelo (Subtasks):
	1.	ğŸ”§ Arquiteto de Infraestrutura:
	â€¢	Define toda a arquitetura: Data Lake, Pipeline de dados, banco SQL, ML pipeline, backend e frontend.
	2.	ğŸ—ï¸ Engenheiro de Dados:
	â€¢	Cria scripts ETL do Data Lake â†’ PostgreSQL.
	â€¢	Faz processamento, limpeza e transformaÃ§Ã£o dos dados.
	3.	ğŸ¤– Cientista de Dados:
	â€¢	Implementa os algoritmos de clusterizaÃ§Ã£o (KMeans, DBSCAN).
	â€¢	Define as features, testa hiperparÃ¢metros e avalia qualidade dos clusters.
	4.	ğŸ–¥ï¸ Desenvolvedor Backend:
	â€¢	Cria API REST em Node.js + Express.
	â€¢	Endpoints: /user/:id/segment, /clusters, /campaigns.
	â€¢	Integra com Redis, RabbitMQ e Smartico API.
	5.	ğŸ¨ Desenvolvedor Frontend:
	â€¢	Cria um dashboard React + Tailwind com grÃ¡ficos, lista de clusters, usuÃ¡rios, campanhas e insights.

â¸»

ğŸ—ï¸ EntregÃ¡veis Gerados:
	â€¢	ğŸ“œ DocumentaÃ§Ã£o TÃ©cnica (.md) com:
	â€¢	Arquitetura completa
	â€¢	Diagrama de dados
	â€¢	DescriÃ§Ã£o dos clusters
	â€¢	ğŸ—‚ï¸ Estrutura de Pastas organizada:
	â€¢	/backend (Node.js)
	â€¢	/frontend (React)
	â€¢	/ml (Python â€“ clusterizaÃ§Ã£o)
	â€¢	/etl (Python ou Node â€“ ingestÃ£o de dados)
	â€¢	ğŸ”¥ Arquivos:
	â€¢	index.js (backend)
	â€¢	App.jsx (frontend)
	â€¢	ml_cluster.py (modelo)
	â€¢	etl_pipeline.py (dados)
	â€¢	ğŸ³ Dockerfile e docker-compose.yaml prontos para deploy.
	â€¢	ğŸ”— Webhook + API Smartico integrados para envio automÃ¡tico dos clusters e perfis.

â¸»

ğŸš€ Output Esperado:

ğŸ† Entregar todo o cÃ³digo backend, frontend, pipelines ML, scripts de integraÃ§Ã£o, alÃ©m de um arquivo .md documentando toda a arquitetura, explicando o funcionamento do sistema, APIs disponÃ­veis, estrutura dos dados e exemplos de payloads.

â¸»

ğŸ§  FinalizaÃ§Ã£o do Prompt:

Execute todas essas tarefas de forma paralela, utilizando UltraThink, Subtask e Hardness, com foco em entregar um sistema funcional, escalÃ¡vel e pronto para deploy, com foco na performance, resiliÃªncia e facilidade de manutenÃ§Ã£o.

# ğŸ“Š CRM Inteligente com Machine Learning e ClusterizaÃ§Ã£o

## ğŸ—ï¸ Arquitetura Geral
- Data Lake (AWS S3, Google Cloud Storage ou Azure)
- Banco de Dados: PostgreSQL
- Cache e Rate Limit: Redis
- Filas de Processamento: RabbitMQ
- Backend API: Node.js + Express
- Frontend: React + Tailwind
- ML Pipeline: Python (Scikit-Learn + Pandas)
- Deploy: Docker + Railway

## ğŸ”— Fluxo de Dados
```
Data Lake â†’ ETL â†’ Banco SQL â†’ ML ClusterizaÃ§Ã£o â†’ DF Final Union â†’ API â†’ CRM (Smartico) â†’ Campanhas
```

## ğŸ§  Pipeline de Machine Learning
- Algoritmos: KMeans, DBSCAN ou HDBSCAN
- Features:
  - Tipo de jogo preferido
  - Ticket mÃ©dio
  - Dias e horÃ¡rios ativos
  - Canal de comunicaÃ§Ã£o preferido
- SaÃ­da: clusters segmentando usuÃ¡rios em perfis comportamentais

## ğŸ—ï¸ Estrutura de Pastas
```
/backend
/frontend
/ml
/etl
/docs
```

## ğŸš€ Backend API (Node.js)
- Rotas:
  - GET `/user/:id/segment`
  - GET `/clusters`
  - POST `/campaigns`
- IntegraÃ§Ã£o com Redis, RabbitMQ e API Smartico

## ğŸ¨ Frontend (React + Tailwind)
- Dashboard:
  - VisualizaÃ§Ã£o de clusters
  - Lista de usuÃ¡rios
  - Insights de comportamento
  - CriaÃ§Ã£o de campanhas

## ğŸ¤– Machine Learning (/ml)
- Script: `ml_cluster.py`
- FunÃ§Ãµes:
  - Processamento de dados
  - ClusterizaÃ§Ã£o
  - GeraÃ§Ã£o do dataframe final

## ğŸ”— IntegraÃ§Ã£o com CRM
- API Smartico:
  - CriaÃ§Ã£o e envio de campanhas automÃ¡ticas
  - Baseado no cluster e comportamento dos usuÃ¡rios

## ğŸ³ Docker
- Dockerfile
- docker-compose.yaml
- Deploy na Railway

## ğŸ“„ DocumentaÃ§Ã£o
- DescriÃ§Ã£o dos clusters
- Exemplo de payloads
- EspecificaÃ§Ã£o da API
- Diagrama de arquitetura
