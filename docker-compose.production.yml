# Production Docker Compose Configuration
# Optimized for high performance, security, and scalability
version: '3.8'

services:
  # Production Database (PostgreSQL)
  postgres:
    image: postgres:15-alpine
    container_name: crmbet_postgres_prod
    environment:
      POSTGRES_DB: crmbet
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --auth-host=scram-sha-256"
      # Performance tuning
      POSTGRES_SHARED_BUFFERS: "4GB"
      POSTGRES_EFFECTIVE_CACHE_SIZE: "12GB"
      POSTGRES_MAINTENANCE_WORK_MEM: "2GB"
      POSTGRES_CHECKPOINT_COMPLETION_TARGET: "0.9"
      POSTGRES_WAL_BUFFERS: "64MB"
      POSTGRES_DEFAULT_STATISTICS_TARGET: "100"
      POSTGRES_RANDOM_PAGE_COST: "1.1"
      POSTGRES_EFFECTIVE_IO_CONCURRENCY: "200"
    ports:
      - "127.0.0.1:5432:5432"  # Bind only to localhost
    volumes:
      - postgres_data_prod:/var/lib/postgresql/data
      - ./docs/sql:/docker-entrypoint-initdb.d:ro
      - ./config/postgres.conf:/etc/postgresql/postgresql.conf:ro
      - postgres_logs:/var/log/postgresql
    networks:
      - crmbet_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d crmbet"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    mem_limit: 8g
    cpus: 4.0
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Production Redis Cluster
  redis:
    image: redis:7-alpine
    container_name: crmbet_redis_prod
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    ports:
      - "127.0.0.1:6379:6379"
    volumes:
      - redis_data_prod:/data
      - ./config/redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - crmbet_network
    command: redis-server /usr/local/etc/redis/redis.conf --requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    mem_limit: 2g
    cpus: 1.0
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Production Message Queue
  rabbitmq:
    image: rabbitmq:3.12-management-alpine
    container_name: crmbet_rabbitmq_prod
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
      RABBITMQ_DEFAULT_VHOST: crmbet_vhost
      RABBITMQ_ERLANG_COOKIE: ${RABBITMQ_ERLANG_COOKIE}
      # Performance tuning
      RABBITMQ_VM_MEMORY_HIGH_WATERMARK: "0.6"
      RABBITMQ_DISK_FREE_LIMIT: "2GB"
    ports:
      - "127.0.0.1:5672:5672"    # AMQP port
      - "127.0.0.1:15672:15672"  # Management UI
    volumes:
      - rabbitmq_data_prod:/var/lib/rabbitmq
      - ./config/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf:ro
      - ./config/enabled_plugins:/etc/rabbitmq/enabled_plugins:ro
    networks:
      - crmbet_network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_port_connectivity"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    mem_limit: 2g
    cpus: 1.0
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Production Backend API (Load Balanced)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.production
      args:
        NODE_ENV: production
        BUILD_DATE: ${BUILD_DATE}
        VERSION: ${VERSION}
    image: crmbet/backend:${VERSION}
    environment:
      NODE_ENV: production
      PORT: 3000
      DATABASE_URL: postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/crmbet?sslmode=prefer
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672/crmbet_vhost
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXPIRES_IN: ${JWT_EXPIRES_IN:-15m}
      BCRYPT_ROUNDS: ${BCRYPT_ROUNDS:-12}
      RATE_LIMIT_WINDOW: ${RATE_LIMIT_WINDOW:-900000}
      RATE_LIMIT_MAX: ${RATE_LIMIT_MAX:-1000}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      SMARTICO_API_URL: ${SMARTICO_API_URL}
      SMARTICO_API_KEY: ${SMARTICO_API_KEY}
      MONITORING_ENABLED: "true"
      METRICS_PORT: 9090
    ports:
      - "3000:3000"
      - "9090:9090"  # Metrics port
    networks:
      - crmbet_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=200m
    mem_limit: 2g
    cpus: 2.0
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 2g
          cpus: '2.0'
        reservations:
          memory: 1g
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Production ML Service
  ml_service:
    build:
      context: ./ml
      dockerfile: Dockerfile.production
      args:
        PYTHON_VERSION: 3.11
        BUILD_DATE: ${BUILD_DATE}
        VERSION: ${VERSION}
    image: crmbet/ml-service:${VERSION}
    environment:
      PYTHONPATH: /app/src
      DATABASE_URL: postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/crmbet
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672/crmbet_vhost
      ML_MODEL_PATH: /app/models
      ML_BATCH_SIZE: ${ML_BATCH_SIZE:-1000}
      ML_WORKERS: ${ML_WORKERS:-4}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      MONITORING_ENABLED: "true"
      METRICS_PORT: 9091
    ports:
      - "8000:8000"
      - "9091:9091"  # Metrics port
    volumes:
      - ml_models_prod:/app/models:ro
      - ml_cache:/app/cache
    networks:
      - crmbet_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 120s
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=500m
    mem_limit: 4g
    cpus: 2.0
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 4g
          cpus: '2.0'
        reservations:
          memory: 2g
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Production ETL Service
  etl_service:
    build:
      context: ./etl
      dockerfile: Dockerfile.production
      args:
        PYTHON_VERSION: 3.11
        BUILD_DATE: ${BUILD_DATE}
        VERSION: ${VERSION}
    image: crmbet/etl-service:${VERSION}
    environment:
      PYTHONPATH: /app/src
      DATABASE_URL: postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/crmbet
      RABBITMQ_URL: amqp://${RABBITMQ_USER}:${RABBITMQ_PASSWORD}@rabbitmq:5672/crmbet_vhost
      DATA_LAKE_URL: ${DATA_LAKE_URL}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION:-us-east-1}
      ETL_BATCH_SIZE: ${ETL_BATCH_SIZE:-5000}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      MONITORING_ENABLED: "true"
      METRICS_PORT: 9092
    ports:
      - "9092:9092"  # Metrics port
    volumes:
      - etl_logs_prod:/app/logs
      - etl_cache:/app/cache
    networks:
      - crmbet_network
    depends_on:
      postgres:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:9092/health')"]
      interval: 120s
      timeout: 30s
      retries: 3
      start_period: 180s
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=1g
    mem_limit: 3g
    cpus: 1.5
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Nginx Reverse Proxy & Load Balancer
  nginx:
    build:
      context: ./nginx
      dockerfile: Dockerfile.production
    image: crmbet/nginx:${VERSION}
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_cache:/var/cache/nginx
      - nginx_logs:/var/log/nginx
    networks:
      - crmbet_network
    depends_on:
      - backend
      - ml_service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    mem_limit: 512m
    cpus: 0.5
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Monitoring Stack
  prometheus:
    image: prom/prometheus:latest
    container_name: crmbet_prometheus_prod
    ports:
      - "127.0.0.1:9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus:ro
      - prometheus_data_prod:/prometheus
    networks:
      - crmbet_network
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.wal-compression'
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    mem_limit: 2g
    cpus: 1.0

  grafana:
    image: grafana/grafana:latest
    container_name: crmbet_grafana_prod
    ports:
      - "127.0.0.1:3001:3000"
    volumes:
      - grafana_data_prod:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_SECURITY_SECRET_KEY: ${GRAFANA_SECRET_KEY}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_ANALYTICS_REPORTING_ENABLED: "false"
    networks:
      - crmbet_network
    depends_on:
      - prometheus
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    mem_limit: 1g
    cpus: 0.5

networks:
  crmbet_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
    driver_opts:
      com.docker.network.bridge.name: crmbet-br0
      com.docker.network.bridge.enable_icc: "true"
      com.docker.network.bridge.enable_ip_masquerade: "true"

volumes:
  postgres_data_prod:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/postgres
  redis_data_prod:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/redis
  rabbitmq_data_prod:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/rabbitmq
  ml_models_prod:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/ml_models
  etl_logs_prod:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/etl_logs
  prometheus_data_prod:
    driver: local
  grafana_data_prod:
    driver: local
  nginx_cache:
    driver: local
  nginx_logs:
    driver: local
  postgres_logs:
    driver: local
  ml_cache:
    driver: local
  etl_cache:
    driver: local